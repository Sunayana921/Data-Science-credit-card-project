{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxJu8nrJizFuzWZxBPzXn3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sunayana921/Data-Science-credit-card-project/blob/main/Creditcard_fraud_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5YMIJJ7SRRR",
        "outputId": "1bd9a7c6-ff61-4e4d-ea82-b473dd381f1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[441   2]\n",
            " [ 23 125]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       443\n",
            "           1       0.98      0.84      0.91       148\n",
            "\n",
            "    accuracy                           0.96       591\n",
            "   macro avg       0.97      0.92      0.94       591\n",
            "weighted avg       0.96      0.96      0.96       591\n",
            "\n",
            "ROC AUC Score: 0.9793713013238972\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"creditcard.csv\")\n",
        "\n",
        "# Simulate additional features\n",
        "np.random.seed(42)\n",
        "num_users = 5000\n",
        "num_merchants = 1000\n",
        "locations = ['NY', 'LA', 'CHI', 'SF', 'HOU', 'MIA', 'SEA', 'ATL']\n",
        "\n",
        "df['UserID'] = np.random.choice([f\"U{i}\" for i in range(num_users)], size=len(df))\n",
        "df['MerchantID'] = np.random.choice([f\"M{i}\" for i in range(num_merchants)], size=len(df))\n",
        "df['TransactionLocation'] = np.random.choice(locations, size=len(df))\n",
        "df['UserHomeLocation'] = np.random.choice(locations, size=len(df))\n",
        "df['LocationMismatch'] = (df['TransactionLocation'] != df['UserHomeLocation']).astype(int)\n",
        "df['UserTxCount'] = df.groupby('UserID').cumcount()\n",
        "df['MerchantAvgAmtDiff'] = df['Amount'] - df.groupby('MerchantID')['Amount'].transform('mean')\n",
        "\n",
        "# Feature engineering\n",
        "df['Hour'] = (df['Time'] // 3600) % 24\n",
        "df['TxCountPerHour'] = df.groupby('Hour')['Amount'].transform('count')\n",
        "df['Amount_Z'] = (df['Amount'] - df['Amount'].mean()) / (df['Amount'].std() + 1e-9)\n",
        "\n",
        "# Select features\n",
        "feature_cols = ['Amount', 'Hour', 'TxCountPerHour', 'Amount_Z',\n",
        "                'LocationMismatch', 'UserTxCount', 'MerchantAvgAmtDiff'] +                [col for col in df.columns if col.startswith('V')]\n",
        "\n",
        "X = df[feature_cols]\n",
        "y = df['Class']\n",
        "\n",
        "# Balance classes via under-sampling\n",
        "fraud_df = df[df['Class'] == 1]\n",
        "normal_df = df[df['Class'] == 0].sample(n=len(fraud_df)*3, random_state=42)\n",
        "balanced_df = pd.concat([fraud_df, normal_df]).sample(frac=1, random_state=42)\n",
        "\n",
        "X_bal = balanced_df[feature_cols]\n",
        "y_bal = balanced_df['Class']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.3, stratify=y_bal, random_state=42)\n",
        "\n",
        "# Model training\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluation\n",
        "y_pred = clf.predict(X_test)\n",
        "y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))"
      ]
    }
  ]
}